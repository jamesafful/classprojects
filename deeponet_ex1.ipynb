{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesafful/classprojects/blob/main/deeponet_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbOycI37jy1a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network(layer_dims, activation='tanh'):\n",
        "\tkinitializer = 'glorot_uniform'\n",
        "\tinput_dim = layer_dims[0]\n",
        "\thidden_layer_dims = layer_dims[1:]\n",
        "\tn_hidden_layers = len(hidden_layer_dims)\n",
        "\tdense_layers = []\n",
        "\tdense_layers.append(keras.Input(shape=(input_dim)))\n",
        "\tfor i in range(n_hidden_layers):\n",
        "\t\tdense_layers.append(\n",
        "\t\t\tlayers.Dense(hidden_layer_dims[i], activation=activation, kernel_initializer=kinitializer, bias_initializer='zeros')\n",
        "\t\t)\n",
        "\tmodel = keras.Sequential(dense_layers)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "RHo6g8-Hk_WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepONet(object):\n",
        "\t\"\"\"docstring for DeepONet\"\"\"\n",
        "\tdef __init__(self,\n",
        "\t\tlayer_sizes_branch,\n",
        "\t\tlayer_sizes_trunk,\n",
        "\t\tactivation_branch,\n",
        "\t\tactivation_trunk\n",
        "\t):\n",
        "\t\tsuper(DeepONet, self).__init__()\n",
        "\t\tself.branch = build_network(layer_sizes_branch,activation_branch)\n",
        "\t\tself.trunk = build_network(layer_sizes_trunk, activation_trunk)\n",
        "\t\tself.b = tf.Variable(tf.zeros(1, dtype=tf.float32))\n",
        "\n",
        "\tdef __call__(self, inputs):\n",
        "\t\tf = inputs[0]\n",
        "\t\tx = inputs[1]\n",
        "\n",
        "\t\tF = self.branch(f)\n",
        "\t\tX = self.trunk(x)\n",
        "\t\tu = tf.einsum(\"bi,ni->bn\", F, X)\n",
        "\n",
        "\t\tu += self.b\n",
        "\n",
        "\t\treturn u"
      ],
      "metadata": {
        "id": "Wi72nH_wlFtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AntiDerivative(object):\n",
        "\t\"\"\"docstring for AntiDerivative\"\"\"\n",
        "\tdef __init__(self, net, train_data, test_data, log_path=None):\n",
        "\t\tsuper(AntiDerivative, self).__init__()\n",
        "\t\tself.net = net\n",
        "\t\tself.train_data = train_data\n",
        "\t\tself.test_data = test_data\n",
        "\t\tself.log_path = log_path\n",
        "\n",
        "\t@tf.function\n",
        "\tdef train_step(self, x_train, u_train):\n",
        "\t\tpflag = True # persistence of gradient tape\n",
        "\t\twith tf.GradientTape(persistent=pflag) as t3:\n",
        "\t\t\tu_hat = self.net(x_train)\n",
        "\t\t\tloss = tf.reduce_mean((u_train - u_hat)**2)\n",
        "\t\tgradients_branch = t3.gradient(loss, self.net.branch.trainable_weights)\n",
        "\t\tgradients_trunk = t3.gradient(loss, self.net.trunk.trainable_weights)\n",
        "\t\tself.optimizer_B.apply_gradients(zip(gradients_branch, self.net.branch.trainable_weights))\n",
        "\t\tself.optimizer_T.apply_gradients(zip(gradients_trunk, self.net.trunk.trainable_weights))\n",
        "\n",
        "\tdef train(self, learning_rate=0.001, epochs=50000):\n",
        "\t\t# setup optimizers\n",
        "\t\tself.optimizer_B = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\t\tself.optimizer_T = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\t\tx_test = self.test_data[\"x_test\"]\n",
        "\t\tu_test = self.test_data[\"u_test\"]\n",
        "\t\t# randomly select test ids for plotting\n",
        "\t\ttest_idx = np.random.randint(0,u_test.shape[0], size=(9,))\n",
        "\n",
        "\t\t# training\n",
        "\t\tfor ep in range(epochs):\n",
        "\t\t\tx_train = self.train_data[\"x_train\"]\n",
        "\t\t\tu_train = self.train_data[\"u_train\"]\n",
        "\t\t\tself.train_step(x_train, u_train)\n",
        "\t\t\tif ep%1000 == 0:\n",
        "\t\t\t\tprint(\"Epoch {}\".format(ep))\n",
        "\t\t\t\tu_hat = self.net(x_test)\n",
        "\n",
        "\t\t\t\t# PLOTTING\n",
        "\t\t\t\tplt_num_row = 3\n",
        "\t\t\t\tplt_num_col = 3\n",
        "\n",
        "\t\t\t\tfig, axs = plt.subplots(plt_num_row, plt_num_col, figsize=(3*plt_num_col,3*plt_num_row),\n",
        "\t\t\t\t\t\t\tsubplot_kw={'aspect': 'auto'}, sharex=True, sharey=True, squeeze=True)\n",
        "\n",
        "\t\t\t\tfor j in range(plt_num_col):\n",
        "\t\t\t\t\tfor i in range(plt_num_row):\n",
        "\t\t\t\t\t\tI = test_idx[j * plt_num_row + i]\n",
        "\t\t\t\t\t\tim = axs[i][j].plot(u_hat[I,:])\n",
        "\t\t\t\t\t\tim = axs[i][j].plot(u_test[I,:])\n",
        "\t\t\t\t\t\taxs[i][j].legend([\"predicted-#\"+str(I), \"ground-truth-#\"+str(I)])\n",
        "\n",
        "\t\t\t\tplot_path = os.path.join(self.log_path, \"plots\")\n",
        "\t\t\t\tif not(os.path.exists(plot_path)):\n",
        "\t\t\t\t\tos.makedirs(plot_path)\n",
        "\n",
        "\t\t\t\tplt.savefig(os.path.join(plot_path, 'contour_' + str(ep) + '.png'))\n",
        "\t\t\t\tplt.close('all')"
      ],
      "metadata": {
        "id": "yF1lSv_myw5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/deeponet_antiderivative_aligned\"\n",
        "work_path = \"/content/\""
      ],
      "metadata": {
        "id": "RbS8lzAfJY76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "d = np.load(os.path.join(\"antiderivative_aligned_train.npz\"), allow_pickle=True)\n",
        "X_train = (d[\"X\"][0].astype(np.float32), d[\"X\"][1].astype(np.float32))\n",
        "y_train = d[\"y\"].astype(np.float32)\n",
        "d = np.load(os.path.join(\"antiderivative_aligned_test.npz\"), allow_pickle=True)\n",
        "X_test = (d[\"X\"][0].astype(np.float32), d[\"X\"][1].astype(np.float32))\n",
        "y_test = d[\"y\"].astype(np.float32)\n",
        "\n",
        "train_data = {\"x_train\":X_train, \"u_train\":y_train}\n",
        "test_data = {\"x_test\":X_test, \"u_test\":y_test}"
      ],
      "metadata": {
        "id": "z4nWcEOKJchH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = y_train.shape[1] # number of sensor points\n",
        "dim_x = 1 # input dimension\n",
        "deeponet = DeepONet([m, 40, 40], [dim_x, 40, 40], \"tanh\", \"tanh\")\n",
        "model = AntiDerivative(deeponet, train_data, test_data, log_path=work_path)\n",
        "model.train(learning_rate=0.001, epochs=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z90y2wQOJkCC",
        "outputId": "28a31837-755a-4f20-e107-0d9a75d50e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Epoch 1000\n",
            "Epoch 2000\n",
            "Epoch 3000\n",
            "Epoch 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jctWcA711uNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}